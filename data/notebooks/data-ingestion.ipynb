{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-03T22:53:25.729199300Z",
     "start_time": "2024-10-03T22:53:25.209566600Z"
    }
   },
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from dateutil import parser\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def parse_dates(date_string):\n",
    "    try:\n",
    "        return parser.parse(date_string)\n",
    "    except ValueError:\n",
    "        return pd.NaT  # Not a Time - pandas' equivalent of NaN for datetime"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-03T22:53:25.731208500Z",
     "start_time": "2024-10-03T22:53:25.728147Z"
    }
   },
   "id": "3df093cf21aee04a",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "con = duckdb.connect(\"E:/duckdb/tennis.duckdb\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-03T22:53:25.745898800Z",
     "start_time": "2024-10-03T22:53:25.731208500Z"
    }
   },
   "id": "682c58d0976b136a",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Betfair - Market summaries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc9e6747353f790d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ConnectionException",
     "evalue": "Connection Error: Connection already closed!",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mConnectionException\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[47], line 15\u001B[0m\n\u001B[0;32m     12\u001B[0m market_summ_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mevent_date\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m market_summ_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mevent_date\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(parse_dates)\n\u001B[0;32m     13\u001B[0m market_summ_df \u001B[38;5;241m=\u001B[39m market_summ_df\u001B[38;5;241m.\u001B[39mquery(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mevent_date <= \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m2098-01-01\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mdrop(columns\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhandicap\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 15\u001B[0m \u001B[43mcon\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mDROP TABLE IF EXISTS market_summaries\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     16\u001B[0m con\u001B[38;5;241m.\u001B[39mexecute(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCREATE TABLE market_summaries AS SELECT * FROM market_summ_df\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mConnectionException\u001B[0m: Connection Error: Connection already closed!"
     ]
    }
   ],
   "source": [
    "market_summ = []\n",
    "for path in glob.glob(\"E:/Data/tennis/market-summaries/*\"):\n",
    "    market = pd.read_csv(path, encoding='latin-1', dtype={'market_id':'str'})\n",
    "    market_summ.append(market)\n",
    "    \n",
    "market_summ_df = pd.concat(market_summ)\n",
    "\n",
    "market_summ_df.loc[market_summ_df['market_id'].str.len() < 11, 'market_id'] = \\\n",
    "    market_summ_df.loc[market_summ_df['market_id'].str.len() < 11, 'market_id'].apply(lambda x: x.ljust(11, '0'))\n",
    "\n",
    "# Assuming your data is in a DataFrame called 'df'\n",
    "market_summ_df['event_date'] = market_summ_df['event_date'].apply(parse_dates)\n",
    "market_summ_df = market_summ_df.query('event_date <= \"2098-01-01\"').drop(columns='handicap')\n",
    "\n",
    "con.execute(\"DROP TABLE IF EXISTS market_summaries\")\n",
    "con.execute(\"CREATE TABLE market_summaries AS SELECT * FROM market_summ_df\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T06:29:48.689669800Z",
     "start_time": "2024-09-30T06:29:23.638476600Z"
    }
   },
   "id": "f345b9301aac4000",
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# con.execute(\"SELECT * FROM market_summaries LIMIT 100\").df()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T06:43:50.161849100Z",
     "start_time": "2024-09-30T06:43:50.149242200Z"
    }
   },
   "id": "3eb7ceb5d8c2e543",
   "execution_count": 64
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Betfair - Competition mappings"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62f69640c311e0a8"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<duckdb.duckdb.DuckDBPyConnection at 0x1a864ec09f0>"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_mappings = []\n",
    "for path in glob.glob(\"E:/Data/tennis/competition-mapping/*\"):\n",
    "    mapping = pd.read_csv(path)\n",
    "    comp_mappings.append(mapping)\n",
    "    \n",
    "comp_mappings_df = pd.concat(comp_mappings)\n",
    "comp_mappings_df['market_id'] = \"1.\" + comp_mappings_df['MARKET_ID'].astype(str).str.pad(9, fillchar='0', side='right')\n",
    "\n",
    "comp_mappings_df.drop(columns='MARKET_ID',inplace=True)\n",
    "\n",
    "con.execute(\"DROP TABLE IF EXISTS competition_mappings\")\n",
    "con.execute(\"CREATE TABLE competition_mappings AS SELECT * FROM comp_mappings_df\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T06:33:44.104781600Z",
     "start_time": "2024-09-30T06:33:41.713554700Z"
    }
   },
   "id": "27c5ce84faaec3d1",
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# con.execute(\"SELECT * FROM competition_mappings LIMIT 100\").df()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T06:44:01.859486600Z",
     "start_time": "2024-09-30T06:44:01.851919300Z"
    }
   },
   "id": "93dde63fd9a6013e",
   "execution_count": 66
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Sofascore - Events"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "640ed41464e3cec0"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3921/3921 [04:43<00:00, 13.82it/s]\n",
      "C:\\Users\\Vlad\\AppData\\Local\\Temp\\ipykernel_13744\\1776706592.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_df['datetime'] = combined_df['startTimestamp'].apply(datetime.fromtimestamp)\n"
     ]
    }
   ],
   "source": [
    "# Directory containing the JSON files\n",
    "directory = r'E:\\Data\\tennis\\sofascore\\events'\n",
    "\n",
    "# List to store DataFrames from each file\n",
    "dfs = []\n",
    "\n",
    "# Function to safely select columns\n",
    "def safe_select_columns(df, columns):\n",
    "    return df.reindex(columns=columns, fill_value=pd.NA)\n",
    "\n",
    "# Loop through all JSON files in the directory\n",
    "for filename in tqdm(os.listdir(directory)):\n",
    "    if filename.endswith('.json'):\n",
    "        # Extract event_fetch_date from filename\n",
    "        event_fetch_date = filename.split('_')[-1].split('.')[0]\n",
    "        \n",
    "        with open(os.path.join(directory, filename), 'r') as f:\n",
    "            data = json.load(f)\n",
    "        events = data['events']\n",
    "        df = pd.json_normalize(events)\n",
    "        # df = safe_select_columns(df, selected_columns)\n",
    "        \n",
    "        # Add event_fetch_date column\n",
    "        df['event_fetch_date'] = event_fetch_date\n",
    "        \n",
    "        dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "combined_df['datetime'] = combined_df['startTimestamp'].apply(datetime.fromtimestamp)\n",
    "\n",
    "filtered_df = (\n",
    "    combined_df.sort_values('event_fetch_date')\n",
    "    .groupby('id')\n",
    "    .last()\n",
    "    .reset_index()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T10:46:32.149649700Z",
     "start_time": "2024-09-30T10:40:45.166806600Z"
    }
   },
   "id": "1d4597d4e3af91ae",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e8ee5e3558e24472b2b1fedea073a94a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<duckdb.duckdb.DuckDBPyConnection at 0x298e218da30>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the desired columns\n",
    "selected_columns = ['id', 'startTimestamp', 'slug', 'groundType', 'tournament.uniqueTournament.name', 'tournament.category.name', 'tournament.uniqueTournament.tennisPoints', 'tournament.uniqueTournament.hasEventPlayerStatistics', 'season.name', 'season.year', 'roundInfo.name', 'status.description', 'homeTeam.name', 'homeTeam.slug', 'homeTeam.shortName', 'homeTeam.country.name', \n",
    "                    'awayTeam.name', 'awayTeam.slug', 'awayTeam.shortName', 'awayTeam.country.name', 'winnerCode',\n",
    "                    'homeScore.period1','homeScore.period2','homeScore.period3','homeScore.period4','homeScore.period5',\n",
    "                    'awayScore.period1','awayScore.period2','awayScore.period3','awayScore.period4','awayScore.period5', 'event_fetch_date', 'datetime']\n",
    "\n",
    "filtered_df = filtered_df[selected_columns].rename(columns={\n",
    "    'tournament.uniqueTournament.name': 'tournament_name', \n",
    "    'tournament.category.name': 'tournament_category', \n",
    "    'tournament.uniqueTournament.tennisPoints': 'tournament_points', \n",
    "    'tournament.uniqueTournament.hasEventPlayerStatistics': 'tournament_has_stats', \n",
    "    'season.name': 'season_name', \n",
    "    'season.year': 'season_year', \n",
    "    'roundInfo.name': 'tournament_round', \n",
    "    'status.description': 'match_status', \n",
    "    'homeTeam.name': 'home_team', \n",
    "    'homeTeam.slug': 'home_team_slug', \n",
    "    'homeTeam.shortName': 'home_team_short', \n",
    "    'hometeam.country.name': 'home_team_country', \n",
    "    'awayTeam.name': 'away_team', \n",
    "    'awayTeam.slug': 'away_team_slug', \n",
    "    'awayTeam.shortName': 'away_team_short', \n",
    "    'awayTeam.country.name': 'away_team_country',\n",
    "    'homeScore.period1': 'home_score_period1',\n",
    "    'homeScore.period2': 'home_score_period2',\n",
    "    'homeScore.period3': 'home_score_period3',\n",
    "    'homeScore.period4': 'home_score_period4',\n",
    "    'homeScore.period5': 'home_score_period5',\n",
    "    'awayScore.period1': 'away_score_period1',\n",
    "    'awayScore.period2': 'away_score_period2',\n",
    "    'awayScore.period3': 'away_score_period3',\n",
    "    'awayScore.period4': 'away_score_period4',\n",
    "    'awayScore.period5': 'away_score_period5'\n",
    "}).drop(columns='startTimestamp')\n",
    "\n",
    "con.execute(\"DROP TABLE IF EXISTS sofascore_events\")\n",
    "con.execute(\"CREATE TABLE sofascore_events AS SELECT * FROM filtered_df\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T10:53:52.147938900Z",
     "start_time": "2024-09-30T10:53:45.876023600Z"
    }
   },
   "id": "9ed0f19ff6874630",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "           id                                             slug groundType  \\\n0   4493462.0                       czech-republic-netherlands       None   \n1   4493464.0                                     japan-canada       None   \n2   4493466.0                                    germany-spain       None   \n3   4493468.0                                 australia-france       None   \n4   4493470.0                                great-britain-usa       None   \n..        ...                                              ...        ...   \n95  4843878.0                                  de-paula-turini       Clay   \n96  4843884.0  andreozzi-demoliner-ratiwatana-sa-ratiwatana-so       Clay   \n97  4843894.0                  alund-pella-kretschmer-satschko       Clay   \n98  4843896.0                     gonzalez-arguello-ghem-souza       Clay   \n99  4843898.0                cunha-romboli-cerretani-shamasdin       Clay   \n\n                  tournament_name tournament_category  tournament_points  \\\n0                       Davis Cup           Davis Cup                NaN   \n1                       Davis Cup           Davis Cup                NaN   \n2                       Davis Cup           Davis Cup                NaN   \n3                       Davis Cup           Davis Cup                NaN   \n4                       Davis Cup           Davis Cup                NaN   \n..                            ...                 ...                ...   \n95  Sao Paulo, Brazil Men Singles          Challenger                NaN   \n96   Sao Paulo, Brazil Men Double          Challenger                NaN   \n97   Sao Paulo, Brazil Men Double          Challenger                NaN   \n98   Sao Paulo, Brazil Men Double          Challenger                NaN   \n99   Sao Paulo, Brazil Men Double          Challenger                NaN   \n\n    tournament_has_stats     season_name season_year   tournament_round  ...  \\\n0                   True  Davis Cup 2010        2010        Round of 16  ...   \n1                  False  Davis Cup 2010        2010              Final  ...   \n2                  False  Davis Cup 2010        2010      Quarterfinals  ...   \n3                   True  Davis Cup 2010        2010         Semifinals  ...   \n4                   True  Davis Cup 2010        2010              Final  ...   \n..                   ...             ...         ...                ...  ...   \n95                 False            None        None  1/16-finals (R32)  ...   \n96                 False            None        None   1/8-finals (R16)  ...   \n97                  True            None        None   1/8-finals (R16)  ...   \n98                 False            None        None   1/8-finals (R16)  ...   \n99                 False            None        None   1/8-finals (R16)  ...   \n\n   home_score_period3 home_score_period4 home_score_period5  \\\n0                 NaN                NaN                NaN   \n1                 NaN                NaN                NaN   \n2                 NaN                NaN                NaN   \n3                 NaN                NaN                NaN   \n4                 NaN                NaN                NaN   \n..                ...                ...                ...   \n95                NaN                NaN                NaN   \n96               10.0                NaN                NaN   \n97                NaN                NaN                NaN   \n98                NaN                NaN                NaN   \n99               11.0                NaN                NaN   \n\n   away_score_period1 away_score_period2 away_score_period3  \\\n0                 NaN                NaN                NaN   \n1                 NaN                NaN                NaN   \n2                 NaN                NaN                NaN   \n3                 NaN                NaN                NaN   \n4                 NaN                NaN                NaN   \n..                ...                ...                ...   \n95                8.0                6.0                NaN   \n96                7.0                6.0                4.0   \n97                NaN                NaN                NaN   \n98                3.0                4.0                NaN   \n99                6.0                7.0                5.0   \n\n   away_score_period4 away_score_period5 event_fetch_date            datetime  \n0                 NaN                NaN       2014-02-01 2014-02-01 01:00:00  \n1                 NaN                NaN       2014-01-31 2014-01-31 17:30:00  \n2                 NaN                NaN       2014-02-01 2014-02-01 01:15:00  \n3                 NaN                NaN       2014-02-01 2014-01-31 23:45:00  \n4                 NaN                NaN       2014-02-01 2014-02-01 07:30:00  \n..                ...                ...              ...                 ...  \n95                NaN                NaN       2014-01-01 2013-12-31 23:55:00  \n96                NaN                NaN       2014-01-01 2013-12-31 23:50:00  \n97                NaN                NaN       2014-01-01 2014-01-01 00:15:00  \n98                NaN                NaN       2014-01-01 2014-01-01 01:00:00  \n99                NaN                NaN       2014-01-01 2014-01-01 03:15:00  \n\n[100 rows x 32 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>slug</th>\n      <th>groundType</th>\n      <th>tournament_name</th>\n      <th>tournament_category</th>\n      <th>tournament_points</th>\n      <th>tournament_has_stats</th>\n      <th>season_name</th>\n      <th>season_year</th>\n      <th>tournament_round</th>\n      <th>...</th>\n      <th>home_score_period3</th>\n      <th>home_score_period4</th>\n      <th>home_score_period5</th>\n      <th>away_score_period1</th>\n      <th>away_score_period2</th>\n      <th>away_score_period3</th>\n      <th>away_score_period4</th>\n      <th>away_score_period5</th>\n      <th>event_fetch_date</th>\n      <th>datetime</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4493462.0</td>\n      <td>czech-republic-netherlands</td>\n      <td>None</td>\n      <td>Davis Cup</td>\n      <td>Davis Cup</td>\n      <td>NaN</td>\n      <td>True</td>\n      <td>Davis Cup 2010</td>\n      <td>2010</td>\n      <td>Round of 16</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2014-02-01</td>\n      <td>2014-02-01 01:00:00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4493464.0</td>\n      <td>japan-canada</td>\n      <td>None</td>\n      <td>Davis Cup</td>\n      <td>Davis Cup</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>Davis Cup 2010</td>\n      <td>2010</td>\n      <td>Final</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2014-01-31</td>\n      <td>2014-01-31 17:30:00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4493466.0</td>\n      <td>germany-spain</td>\n      <td>None</td>\n      <td>Davis Cup</td>\n      <td>Davis Cup</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>Davis Cup 2010</td>\n      <td>2010</td>\n      <td>Quarterfinals</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2014-02-01</td>\n      <td>2014-02-01 01:15:00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4493468.0</td>\n      <td>australia-france</td>\n      <td>None</td>\n      <td>Davis Cup</td>\n      <td>Davis Cup</td>\n      <td>NaN</td>\n      <td>True</td>\n      <td>Davis Cup 2010</td>\n      <td>2010</td>\n      <td>Semifinals</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2014-02-01</td>\n      <td>2014-01-31 23:45:00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4493470.0</td>\n      <td>great-britain-usa</td>\n      <td>None</td>\n      <td>Davis Cup</td>\n      <td>Davis Cup</td>\n      <td>NaN</td>\n      <td>True</td>\n      <td>Davis Cup 2010</td>\n      <td>2010</td>\n      <td>Final</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2014-02-01</td>\n      <td>2014-02-01 07:30:00</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>4843878.0</td>\n      <td>de-paula-turini</td>\n      <td>Clay</td>\n      <td>Sao Paulo, Brazil Men Singles</td>\n      <td>Challenger</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>None</td>\n      <td>None</td>\n      <td>1/16-finals (R32)</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8.0</td>\n      <td>6.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2014-01-01</td>\n      <td>2013-12-31 23:55:00</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>4843884.0</td>\n      <td>andreozzi-demoliner-ratiwatana-sa-ratiwatana-so</td>\n      <td>Clay</td>\n      <td>Sao Paulo, Brazil Men Double</td>\n      <td>Challenger</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>None</td>\n      <td>None</td>\n      <td>1/8-finals (R16)</td>\n      <td>...</td>\n      <td>10.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7.0</td>\n      <td>6.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2014-01-01</td>\n      <td>2013-12-31 23:50:00</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>4843894.0</td>\n      <td>alund-pella-kretschmer-satschko</td>\n      <td>Clay</td>\n      <td>Sao Paulo, Brazil Men Double</td>\n      <td>Challenger</td>\n      <td>NaN</td>\n      <td>True</td>\n      <td>None</td>\n      <td>None</td>\n      <td>1/8-finals (R16)</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2014-01-01</td>\n      <td>2014-01-01 00:15:00</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>4843896.0</td>\n      <td>gonzalez-arguello-ghem-souza</td>\n      <td>Clay</td>\n      <td>Sao Paulo, Brazil Men Double</td>\n      <td>Challenger</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>None</td>\n      <td>None</td>\n      <td>1/8-finals (R16)</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2014-01-01</td>\n      <td>2014-01-01 01:00:00</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>4843898.0</td>\n      <td>cunha-romboli-cerretani-shamasdin</td>\n      <td>Clay</td>\n      <td>Sao Paulo, Brazil Men Double</td>\n      <td>Challenger</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>None</td>\n      <td>None</td>\n      <td>1/8-finals (R16)</td>\n      <td>...</td>\n      <td>11.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>5.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2014-01-01</td>\n      <td>2014-01-01 03:15:00</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 32 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"SELECT * FROM sofascore_events LIMIT 100\").df()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T10:54:25.472530600Z",
     "start_time": "2024-09-30T10:54:25.439793800Z"
    }
   },
   "id": "e829cad1aad3a527",
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Sofascore - Match stats"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8043071ffc435b57"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 12212/656787 [00:06<05:25, 1979.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error decoding JSON in file E:/Data\\tennis\\sofascore\\match-stats\\match_stat_10182423.json: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 332249/656787 [04:18<04:36, 1175.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error decoding JSON in file E:/Data\\tennis\\sofascore\\match-stats\\match_stat_7051288.json: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 585916/656787 [07:58<01:07, 1054.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error decoding JSON in file E:/Data\\tennis\\sofascore\\match-stats\\match_stat_8570059.json: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 656787/656787 [09:00<00:00, 1215.00it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def flatten_json(json_data, match_id):\n",
    "    rows = []\n",
    "    \n",
    "    for period in json_data.get('statistics', []):\n",
    "        period_name = period.get('period', '')\n",
    "        \n",
    "        for group in period.get('groups', []):\n",
    "            group_name = group.get('groupName', '')\n",
    "            \n",
    "            for item in group.get('statisticsItems', []):\n",
    "                row = {\n",
    "                    'match_id': match_id,\n",
    "                    'period': period_name,\n",
    "                    'group': group_name,\n",
    "                    'name': item.get('name', ''),\n",
    "                    'home': item.get('home', ''),\n",
    "                    'away': item.get('away', ''),\n",
    "                    'compareCode': item.get('compareCode', ''),\n",
    "                    'statisticsType': item.get('statisticsType', ''),\n",
    "                    'valueType': item.get('valueType', ''),\n",
    "                    'homeValue': item.get('homeValue', ''),\n",
    "                    'awayValue': item.get('awayValue', ''),\n",
    "                    'key': item.get('key', '')\n",
    "                }\n",
    "                \n",
    "                if 'homeTotal' in item:\n",
    "                    row['homeTotal'] = item['homeTotal']\n",
    "                if 'awayTotal' in item:\n",
    "                    row['awayTotal'] = item['awayTotal']\n",
    "                \n",
    "                rows.append(row)\n",
    "    \n",
    "    return rows\n",
    "\n",
    "def process_files(folder_path, con, chunk_size=10000):\n",
    "    all_data = []\n",
    "    table_created = False\n",
    "    \n",
    "    for file_path in tqdm(glob.glob(os.path.join(folder_path, '*.json'))):\n",
    "        match_id = os.path.splitext(os.path.basename(file_path))[0].split('_')[-1]\n",
    "        \n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                json_data = json.load(file)\n",
    "                all_data.extend(flatten_json(json_data, match_id))\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON in file {file_path}: {str(e)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file_path}: {str(e)}\")\n",
    "        \n",
    "        # If we've collected enough rows or it's the first chunk, process the data\n",
    "        if len(all_data) >= chunk_size or not table_created:\n",
    "            df = pd.DataFrame(all_data)\n",
    "            \n",
    "            if not table_created:\n",
    "                # Create the table using the first chunk of data\n",
    "                con.execute(\"DROP TABLE IF EXISTS sofascore_match_stats\")\n",
    "                con.execute(\"CREATE TABLE sofascore_match_stats AS SELECT * FROM df LIMIT 0\")\n",
    "                table_created = True\n",
    "            \n",
    "            # Insert the data\n",
    "            con.execute(\"INSERT INTO sofascore_match_stats SELECT * FROM df\")\n",
    "            all_data.clear()\n",
    "    \n",
    "    # Write any remaining data\n",
    "    if all_data:\n",
    "        df = pd.DataFrame(all_data)\n",
    "        con.execute(\"INSERT INTO sofascore_match_stats SELECT * FROM df\")\n",
    "\n",
    "# Usage\n",
    "folder_path = os.path.join('E:/', 'Data', 'tennis', 'sofascore', 'match-stats')\n",
    "\n",
    "# Process files and insert data in chunks\n",
    "process_files(folder_path, con)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-03T06:47:30.041359500Z",
     "start_time": "2024-10-03T06:38:27.447485900Z"
    }
   },
   "id": "9b80131cc1492f48",
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Sofascore - Point by point"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b773c6dd7b05397a"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "    match_id period    group                  name         home         away  \\\n0   10000150    ALL  Service                  Aces            1            4   \n1   10000150    ALL  Service         Double faults            2            5   \n2   10000150    ALL  Service           First serve  26/47 (55%)  32/53 (60%)   \n3   10000150    ALL  Service          Second serve  19/21 (90%)  16/21 (76%)   \n4   10000150    ALL  Service    First serve points  16/26 (62%)  26/32 (81%)   \n..       ...    ...      ...                   ...          ...          ...   \n95  10000152    2ND  Service  Service games played            4            4   \n96  10000152    2ND  Service    Break points saved    2/3 (66%)    1/4 (25%)   \n97  10000152    2ND   Points    Service points won           13            9   \n98  10000152    2ND   Points   Receiver points won           14            8   \n99  10000152    2ND   Points   Max points in a row            8            4   \n\n    compareCode statisticsType valueType  homeValue  awayValue  \\\n0             2       positive     event          0          2   \n1             2       negative     event          0          2   \n2             2       positive      team         42         32   \n3             1       positive      team         22          2   \n4             2       positive      team         22          8   \n..          ...            ...       ...        ...        ...   \n95            3       positive     event          2          6   \n96            1       positive      team          2          0   \n97            1       positive     event         10         16   \n98            1       positive     event         14         14   \n99            1       positive     event          4          4   \n\n                         key  homeTotal  awayTotal  \n0                       aces        NaN        NaN  \n1               doubleFaults        NaN        NaN  \n2         firstServeAccuracy       47.0       53.0  \n3        secondServeAccuracy       21.0       21.0  \n4   firstServePointsAccuracy       26.0       32.0  \n..                       ...        ...        ...  \n95         serviceGamesTotal        NaN        NaN  \n96          breakPointsSaved        3.0        4.0  \n97       servicePointsScored        NaN        NaN  \n98      receiverPointsScored        NaN        NaN  \n99            maxPointsInRow        NaN        NaN  \n\n[100 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>match_id</th>\n      <th>period</th>\n      <th>group</th>\n      <th>name</th>\n      <th>home</th>\n      <th>away</th>\n      <th>compareCode</th>\n      <th>statisticsType</th>\n      <th>valueType</th>\n      <th>homeValue</th>\n      <th>awayValue</th>\n      <th>key</th>\n      <th>homeTotal</th>\n      <th>awayTotal</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10000150</td>\n      <td>ALL</td>\n      <td>Service</td>\n      <td>Aces</td>\n      <td>1</td>\n      <td>4</td>\n      <td>2</td>\n      <td>positive</td>\n      <td>event</td>\n      <td>0</td>\n      <td>2</td>\n      <td>aces</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10000150</td>\n      <td>ALL</td>\n      <td>Service</td>\n      <td>Double faults</td>\n      <td>2</td>\n      <td>5</td>\n      <td>2</td>\n      <td>negative</td>\n      <td>event</td>\n      <td>0</td>\n      <td>2</td>\n      <td>doubleFaults</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10000150</td>\n      <td>ALL</td>\n      <td>Service</td>\n      <td>First serve</td>\n      <td>26/47 (55%)</td>\n      <td>32/53 (60%)</td>\n      <td>2</td>\n      <td>positive</td>\n      <td>team</td>\n      <td>42</td>\n      <td>32</td>\n      <td>firstServeAccuracy</td>\n      <td>47.0</td>\n      <td>53.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10000150</td>\n      <td>ALL</td>\n      <td>Service</td>\n      <td>Second serve</td>\n      <td>19/21 (90%)</td>\n      <td>16/21 (76%)</td>\n      <td>1</td>\n      <td>positive</td>\n      <td>team</td>\n      <td>22</td>\n      <td>2</td>\n      <td>secondServeAccuracy</td>\n      <td>21.0</td>\n      <td>21.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10000150</td>\n      <td>ALL</td>\n      <td>Service</td>\n      <td>First serve points</td>\n      <td>16/26 (62%)</td>\n      <td>26/32 (81%)</td>\n      <td>2</td>\n      <td>positive</td>\n      <td>team</td>\n      <td>22</td>\n      <td>8</td>\n      <td>firstServePointsAccuracy</td>\n      <td>26.0</td>\n      <td>32.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>10000152</td>\n      <td>2ND</td>\n      <td>Service</td>\n      <td>Service games played</td>\n      <td>4</td>\n      <td>4</td>\n      <td>3</td>\n      <td>positive</td>\n      <td>event</td>\n      <td>2</td>\n      <td>6</td>\n      <td>serviceGamesTotal</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>10000152</td>\n      <td>2ND</td>\n      <td>Service</td>\n      <td>Break points saved</td>\n      <td>2/3 (66%)</td>\n      <td>1/4 (25%)</td>\n      <td>1</td>\n      <td>positive</td>\n      <td>team</td>\n      <td>2</td>\n      <td>0</td>\n      <td>breakPointsSaved</td>\n      <td>3.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>10000152</td>\n      <td>2ND</td>\n      <td>Points</td>\n      <td>Service points won</td>\n      <td>13</td>\n      <td>9</td>\n      <td>1</td>\n      <td>positive</td>\n      <td>event</td>\n      <td>10</td>\n      <td>16</td>\n      <td>servicePointsScored</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>10000152</td>\n      <td>2ND</td>\n      <td>Points</td>\n      <td>Receiver points won</td>\n      <td>14</td>\n      <td>8</td>\n      <td>1</td>\n      <td>positive</td>\n      <td>event</td>\n      <td>14</td>\n      <td>14</td>\n      <td>receiverPointsScored</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>10000152</td>\n      <td>2ND</td>\n      <td>Points</td>\n      <td>Max points in a row</td>\n      <td>8</td>\n      <td>4</td>\n      <td>1</td>\n      <td>positive</td>\n      <td>event</td>\n      <td>4</td>\n      <td>4</td>\n      <td>maxPointsInRow</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 14 columns</p>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"SELECT * FROM sofascore_match_stats LIMIT 100\").df()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-03T06:57:29.227333700Z",
     "start_time": "2024-10-03T06:57:29.136767600Z"
    }
   },
   "id": "39e740b6993298c7",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 9381/112517 [00:02<00:32, 3147.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Unable to parse JSON in file E:/Data\\tennis\\sofascore\\point-by-point-itf\\pbp_8167921.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 67540/112517 [00:21<00:13, 3245.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Unable to parse JSON in file E:/Data\\tennis\\sofascore\\point-by-point-itf\\pbp_8912304.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 111429/112517 [00:35<00:00, 2963.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Unable to parse JSON in file E:/Data\\tennis\\sofascore\\point-by-point-itf\\pbp_9973625.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112517/112517 [00:35<00:00, 3134.54it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "edd3dcbc09424f21bc3e05e2fa1decc4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<duckdb.duckdb.DuckDBPyConnection at 0x1fd1bd0a2b0>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def flatten_json(json_data, match_id):\n",
    "    rows = []\n",
    "    \n",
    "    if 'pointByPoint' not in json_data or not json_data['pointByPoint']:\n",
    "        # print(f\"Warning: No point-by-point data found for match {match_id}\")\n",
    "        return rows\n",
    "\n",
    "    for set_data in json_data['pointByPoint']:\n",
    "        set_number = set_data.get('set', 'Unknown')\n",
    "        \n",
    "        for game in set_data.get('games', []):\n",
    "            game_number = game.get('game', 'Unknown')\n",
    "            \n",
    "            for point in game.get('points', []):\n",
    "                row = {\n",
    "                    'match_id': match_id,\n",
    "                    'set': set_number,\n",
    "                    'game': game_number,\n",
    "                    'homePoint': point.get('homePoint', 'Unknown'),\n",
    "                    'awayPoint': point.get('awayPoint', 'Unknown'),\n",
    "                    'pointDescription': point.get('pointDescription', 'Unknown'),\n",
    "                    'homePointType': point.get('homePointType', 'Unknown'),\n",
    "                    'awayPointType': point.get('awayPointType', 'Unknown')\n",
    "                }\n",
    "                rows.append(row)\n",
    "            \n",
    "            # Add a row for the game score if it exists\n",
    "            score = game.get('score')\n",
    "            if score:\n",
    "                row = {\n",
    "                    'match_id': match_id,\n",
    "                    'set': set_number,\n",
    "                    'game': game_number,\n",
    "                    'homePoint': 'GAME',\n",
    "                    'awayPoint': 'GAME',\n",
    "                    'pointDescription': -1,  # Use -1 to indicate this is a game score\n",
    "                    'homePointType': score.get('homeScore', 'Unknown'),\n",
    "                    'awayPointType': score.get('awayScore', 'Unknown'),\n",
    "                    'serving': score.get('serving', 'Unknown'),\n",
    "                    'scoring': score.get('scoring', 'Unknown')\n",
    "                }\n",
    "                rows.append(row)\n",
    "    \n",
    "    return rows\n",
    "\n",
    "def process_files(folder_path):\n",
    "    all_data = []\n",
    "    \n",
    "    for file_path in tqdm(glob.glob(os.path.join(folder_path, '*.json'))[450000:]):\n",
    "        match_id = os.path.splitext(os.path.basename(file_path))[0].split('_')[-1]\n",
    "        \n",
    "        try:\n",
    "            with open(file_path, 'r') as file:\n",
    "                json_data = json.load(file)\n",
    "                all_data.extend(flatten_json(json_data, match_id))\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Warning: Unable to parse JSON in file {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file_path}: {str(e)}\")\n",
    "    \n",
    "    return pd.DataFrame(all_data)\n",
    "\n",
    "# Usage\n",
    "folder_path = os.path.join('E:/', 'Data', 'tennis', 'sofascore', 'point-by-point-itf')\n",
    "df = process_files(folder_path)\n",
    "\n",
    "# con.execute(\"DROP TABLE IF EXISTS sofascore_point_by_point\")\n",
    "con.execute(\"INSERT INTO sofascore_point_by_point SELECT * FROM df\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-03T23:03:16.421385900Z",
     "start_time": "2024-10-03T23:02:13.447988700Z"
    }
   },
   "id": "90a65f4f2839172b",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "con.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-03T23:07:46.870105400Z",
     "start_time": "2024-10-03T23:07:46.772753200Z"
    }
   },
   "id": "e1168d8681e6731b",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "    match_id  set  game homePoint awayPoint  pointDescription  homePointType  \\\n0   10000273    3     8         0        15                 0              5   \n1   10000273    3     8         0        30                 0              5   \n2   10000273    3     8         0        40                 0              5   \n3   10000273    3     8      GAME      GAME                -1              2   \n4   10000273    3     7         0        15                 0              5   \n..       ...  ...   ...       ...       ...               ...            ...   \n95  10000273    1    13         1         0                 0              1   \n96  10000273    1    13         1         1                 0              5   \n97  10000273    1    13         2         1                 0              6   \n98  10000273    1    13         3         1                 0              1   \n99  10000273    1    13         3         2                 0              5   \n\n    awayPointType  serving  scoring  \n0               1      NaN      NaN  \n1               1      NaN      NaN  \n2               3      NaN      NaN  \n3               6      2.0      2.0  \n4               1      NaN      NaN  \n..            ...      ...      ...  \n95              5      NaN      NaN  \n96              1      NaN      NaN  \n97              5      NaN      NaN  \n98              5      NaN      NaN  \n99              6      NaN      NaN  \n\n[100 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>match_id</th>\n      <th>set</th>\n      <th>game</th>\n      <th>homePoint</th>\n      <th>awayPoint</th>\n      <th>pointDescription</th>\n      <th>homePointType</th>\n      <th>awayPointType</th>\n      <th>serving</th>\n      <th>scoring</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10000273</td>\n      <td>3</td>\n      <td>8</td>\n      <td>0</td>\n      <td>15</td>\n      <td>0</td>\n      <td>5</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10000273</td>\n      <td>3</td>\n      <td>8</td>\n      <td>0</td>\n      <td>30</td>\n      <td>0</td>\n      <td>5</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10000273</td>\n      <td>3</td>\n      <td>8</td>\n      <td>0</td>\n      <td>40</td>\n      <td>0</td>\n      <td>5</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10000273</td>\n      <td>3</td>\n      <td>8</td>\n      <td>GAME</td>\n      <td>GAME</td>\n      <td>-1</td>\n      <td>2</td>\n      <td>6</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10000273</td>\n      <td>3</td>\n      <td>7</td>\n      <td>0</td>\n      <td>15</td>\n      <td>0</td>\n      <td>5</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>10000273</td>\n      <td>1</td>\n      <td>13</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>10000273</td>\n      <td>1</td>\n      <td>13</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>5</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>10000273</td>\n      <td>1</td>\n      <td>13</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>6</td>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>10000273</td>\n      <td>1</td>\n      <td>13</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>10000273</td>\n      <td>1</td>\n      <td>13</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0</td>\n      <td>5</td>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 10 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"SELECT * FROM sofascore_point_by_point LIMIT 100\").df()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-03T23:04:07.939921800Z",
     "start_time": "2024-10-03T23:04:07.927282700Z"
    }
   },
   "id": "c3fab4aabd8fb2a9",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "154291a8424ffbf3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
