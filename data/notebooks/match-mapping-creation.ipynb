{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import duckdb\n",
    "import re\n",
    "import unidecode"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-06T23:14:08.921768300Z",
     "start_time": "2024-10-06T23:14:08.542475300Z"
    }
   },
   "id": "fb3bea947a4f162a",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def process_name(name, words_to_reverse, slug=True, first_name_initial=None):\n",
    "    name = name.lower()\n",
    "    name = unidecode.unidecode(name)\n",
    "    name = re.sub('-', ' ', name)\n",
    "    name = re.sub(r'[^a-z\\s]', '', name)\n",
    "    \n",
    "    words = name.split()\n",
    "    \n",
    "    if words_to_reverse > 0:\n",
    "        if len(words) > words_to_reverse:\n",
    "            words = words[words_to_reverse:] + words[0:words_to_reverse]\n",
    "            if first_name_initial:\n",
    "                words[0] = words[0][0]\n",
    "        \n",
    "    if slug:\n",
    "        name = '-'.join(words)\n",
    "    else:\n",
    "        name = ' '.join(words)\n",
    "        \n",
    "    return name\n",
    "\n",
    "def unpivot_events(df):\n",
    "    # Create a DataFrame for home teams\n",
    "    home_df = df[['id', 'datetime', 'home_clean_name', 'index_home']]\n",
    "    home_df['team_type'] = 'home'\n",
    "    home_df = home_df.rename(columns={'home_clean_name': 'team_name', 'index_home': 'index'})\n",
    "\n",
    "    # Create a DataFrame for away teams\n",
    "    away_df = df[['id', 'datetime', 'away_clean_name', 'index_away']]\n",
    "    away_df['team_type'] = 'away'\n",
    "    away_df = away_df.rename(columns={'away_clean_name': 'team_name', 'index_away': 'index'})\n",
    "\n",
    "    # Combine the two DataFrames\n",
    "    result = pd.concat([home_df, away_df], ignore_index=True)\n",
    "\n",
    "    # Sort the result\n",
    "    result = result.sort_values(['id', 'team_type']).reset_index(drop=True)\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-06T23:15:54.341925Z",
     "start_time": "2024-10-06T23:15:54.322926300Z"
    }
   },
   "id": "903065bbd13efe38",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "con = duckdb.connect(\"E:/duckdb/tennis.duckdb\", read_only=True)\n",
    "tennis_markets = con.execute(\"\"\"\n",
    "SELECT *\n",
    "\n",
    "FROM competition_mappings c\n",
    "INNER JOIN market_summaries m\n",
    "ON c.market_id = m.market_id\n",
    "\"\"\").df()\n",
    "\n",
    "excluded_selection_names = pd.read_csv('../mappings/excluded_selection_names.csv', header=None)[0].tolist()\n",
    "\n",
    "tennis_markets = tennis_markets[~tennis_markets['selection_name'].str.contains(\"/\")]\n",
    "tennis_markets = tennis_markets[~tennis_markets['selection_name'].isin(excluded_selection_names)]\n",
    "tennis_markets['bf_name'] = [process_name(x, 0, False) for x in tennis_markets['selection_name']]\n",
    "tennis_markets['FORMATTED_DATE'] = pd.to_datetime(tennis_markets['FORMATTED_DATE'])\n",
    "\n",
    "sofascore_events = con.execute(\"SELECT * FROM sofascore_events WHERE tournament_category IN ('ATP','WTA','Challenger','ITF Men','ITF Women','WTA 125')\").df()\n",
    "\n",
    "sofascore_events = sofascore_events[~sofascore_events['home_team'].str.contains('/')]\n",
    "sofascore_events = sofascore_events[~sofascore_events['away_team'].str.contains('/')]\n",
    "sofascore_events = sofascore_events[sofascore_events['match_status'] != 'Not started']\n",
    "sofascore_events['event_fetch_date'] = pd.to_datetime(sofascore_events['event_fetch_date'])\n",
    "\n",
    "sofascore_events['home_clean_name'] = [process_name(x, 1, False) for x in sofascore_events['home_team_slug']]\n",
    "sofascore_events['away_clean_name'] = [process_name(x, 1, False) for x in sofascore_events['away_team_slug']]\n",
    "\n",
    "con.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-06T23:15:47.294370200Z",
     "start_time": "2024-10-06T23:15:39.314009400Z"
    }
   },
   "id": "61e0618a5a1ddce0",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-06T23:16:58.908196700Z",
     "start_time": "2024-10-06T23:15:55.664389300Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vlad\\AppData\\Local\\Temp\\ipykernel_25788\\539505262.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  home_df['team_type'] = 'home'\n",
      "C:\\Users\\Vlad\\AppData\\Local\\Temp\\ipykernel_25788\\539505262.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  away_df['team_type'] = 'away'\n",
      "C:\\Users\\Vlad\\AppData\\Local\\Temp\\ipykernel_25788\\1792948159.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tennis_markets_with_mapping_short['index'] = tennis_markets_with_mapping_short['index'].astype(int)\n"
     ]
    }
   ],
   "source": [
    "name_mapping = pd.read_csv('../mappings/player_name_mapping.csv')\n",
    "\n",
    "tennis_markets_with_mapping = tennis_markets.merge(name_mapping, left_on='bf_name', right_on='name')\n",
    "events_short = sofascore_events.merge(name_mapping, left_on='home_clean_name', right_on='name').merge(name_mapping,\n",
    "                                                                                                      left_on='away_clean_name',\n",
    "                                                                                                      right_on='name',\n",
    "                                                                                                      suffixes=('_home',\n",
    "                                                                                                                '_away'))[\n",
    "    ['id', 'datetime', 'home_clean_name', 'away_clean_name', 'index_home', 'index_away']]\n",
    "events_short['id'] = events_short['id'].astype(int)\n",
    "\n",
    "events_short_unpiv = unpivot_events(events_short)\n",
    "tennis_markets_with_mapping_short = tennis_markets_with_mapping[['market_id', 'event_date', 'name', 'index']]\n",
    "tennis_markets_with_mapping_short['index'] = tennis_markets_with_mapping_short['index'].astype(int)\n",
    "group_counts = tennis_markets_with_mapping_short.groupby('market_id').size()\n",
    "valid_market_ids = group_counts[group_counts == 2].index\n",
    "tennis_markets_with_mapping_short = tennis_markets_with_mapping_short[\n",
    "    tennis_markets_with_mapping_short['market_id'].isin(valid_market_ids)]\n",
    "tennis_markets_with_mapping_short = tennis_markets_with_mapping_short.reset_index(drop=True)\n",
    "\n",
    "events_short_unpiv['datetime'] = pd.to_datetime(events_short_unpiv['datetime'])\n",
    "tennis_markets_with_mapping_short['event_date'] = pd.to_datetime(tennis_markets_with_mapping_short['event_date'])\n",
    "\n",
    "# Create sorted index pairs for joining\n",
    "events_short_unpiv['sort_key'] = events_short_unpiv.groupby('id')['index'].transform(\n",
    "    lambda x: ','.join(map(str, sorted(x))))\n",
    "tennis_markets_with_mapping_short['sort_key'] = tennis_markets_with_mapping_short.groupby('market_id')[\n",
    "    'index'].transform(lambda x: ','.join(map(str, sorted(x))))\n",
    "\n",
    "# Perform the join\n",
    "merged = pd.merge(events_short_unpiv, tennis_markets_with_mapping_short, on='sort_key')\n",
    "# Calculate time difference\n",
    "merged['time_diff'] = abs(merged['datetime'] - merged['event_date']).dt.days\n",
    "\n",
    "merged[['id', 'market_id', 'time_diff']].drop_duplicates().query('time_diff == 0').to_csv(\n",
    "    '../mappings/market_match_mapping.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
